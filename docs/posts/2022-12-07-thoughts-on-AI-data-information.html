<p>If you have been a little active on social tech media the last weeks, you may have seen the new AI chatbot called chatGPT. Check out <a href="https://fosstodon.org/tags/chatGPT">these posts</a> on Mastodon for instance. Besides some workarounds that allow you to generate programs <a href="https://zacdenham.com/blog/narrative-manipulation-convincing-gpt-chat-to-write-a-python-program-to-eradicate-humanity">that eradicate humanity</a>, this model is quite impressive and generates pretty good <em>information</em>—or so it seems. Probably everybody playing around with it is wondering whether it, or some equivalent, will replace Google and Wikipedia medium term.</p>
<p>Recently I read a few books about information theory looking for a clear definition of what the terms <em>data</em> and <em>information</em> that appear in my job title as data engineer in the IT industry actually mean. Everyone <em>kind of</em> knows what they mean but could it be made precise? I have been exposed to information science for quite a while from the Bayesian angle, but this particular reading effort was inspired by Melanie Mitchell’s book “Complexity” that has an example of cellular automata naturally self-organizing to do information processing under evolutionary pressure, Douglas Hofstadter’s book “Gödel, Escher, Bach: An Eternal Golden Braid” that talks a lot about the meaning of symbolic representations and formalisms that process them, James Gleick’s “The Information” that is a great summary of the history of information processing, and the accessible mathematical refresher <a href="https://perso.telecom-paristech.fr/rioul/publis/201811rioul.pdf">here</a>.</p>
<p>Researching a bit further, I found out about the <a href="https://en.wikipedia.org/wiki/DIKW_pyramid">Data-Information-Knowledge-Wisdom (DIKW) model</a> that looks at this from the philosophy side. An interesting article here is <a href="http://www.success.co.il/is/zins_definitions_dik.pdf">Chaim Zins’ collection of definitions</a> of the terms data, information, knowledge from a survey that was sent out to leading scholars in the field of Information Science.</p>
<p>After reading all this stuff one essential point became clear to me: Data is valuable whenever it represents something in the real world. Information is valuable if it allows us to do or understand something in the real world. This essential link to the real world is something I know from my work in academia where among thousands of possible conclusive theories, those are valuable science that actually describe nature. It is very easy to create and get lost in beautiful emptiness.</p>
<p>Now, I think that, besides other problems, chatGPT suffers from a very weak link to reality. In other words, it can’t produce more than accidental information, knowledge and wisdom right now. The main reason is that it’s <em>not optimized to represent the real world accurately</em>. It’s optimized to represent representations of <em>some</em> world. Being trained indiscriminately on text that is spread widely around the internet it can’t really distinguish between fantasy and a non-fantasy. What is possible hypothetically is not what always actually is. There <em>could</em> be a universe with dragons flying etc…, but this is not happening in our universe.</p>
<p>In my view, a search engine should provide information and not show indiscriminately random data to the user that looks like information but actually isn’t. And chatGPT is optimized to produce data that looks like information because it’s vaguely plausible. When soon there is no way anymore to filter out what is actually true from heuristics like quality of presentation, trustworthiness of the source will become extremely important. The tragic of it is that vanilla Google also doesn’t really discriminate between what’s true and what isn’t. But its concept of domain authority at least vaguely spits our more trustworthy sources that lots of others rely on. Quality journalism goes further than that because there is a human being who actually lives in the real world and can test whether what they write is true.</p>
